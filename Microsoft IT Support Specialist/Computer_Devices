- Intro To Computing Devices:

  - What is a Driver?

    - A Driver is a software component that lets the operating system and a device communicate. For example,
      when an app needs to read data from a device, it calls a function implemented by the operating system.
      The operating system then calls a function implemented by the driver. The Driver, usually devoloped by
      the device's manufacturer, knows how to communicate with the device hardware to get the data. Once the
      driver get the data, it gives it back to the operating system. which then gives it back to the app.

          {Application} <--> {Windows Operating System} <--> {Driver} <--> {Device}

  - Expanding The Definition:

    - Drivers don't always have to be developed by the device's manufacturer. If a device follows a published hardware standard, Microsoft can write the driver, so the device designer doesn't have to provide one.

    - Not all drivers communicate directly witha device. Often, several drivers layered in a driver stack take part in an I/O request. The conventional way to visualize the stack is with the first participant at the top and the last participant at the bottom, as shown in this diagram. Some drivers in the stack change the request from one format to another. These drivers don't communicate directly with the device. Instead, they chage the request and pass it to drivers that are lower in the stack.

    {Application} <--> {Windows Operating System} <--> {Driver1 Filter Driver} <--> {Driver2 Filter Driver} <--> {Driver3 function driver} <--> {Device}

    - Function Driver: The driver that communicates directly with the deivice is calle dthe function driver.
    - Filter Driver: Drivers that do auxiliary processing are called Filter drivers.

    - Some filter drivers observe and record information about I/O requests but don't actively take part in them. For example, some gilter drivers act as verifiers to make sure the other drivers in the stack handle the I/O request correctly.

  - We can refine our definition of a driver as any software component that observes or participates in the communication between the operating system and a device.

  - Software Drivers:

    - Our expanded definition is reasonably accurate but is stil incomplete because some drivers aren't associated with any hardware device at all.
    - For example, if you need to write a tool that accesses core operating system data structures, you can splt the tool into two components. The first component runs in user mode and presents the user interface. The second component runs in kernal mode and accesses the core operating system data. The component that runs in user mode is called application, and the componment that runs in kernal mode is called a software driver. A software driver isn't associate with a hardware driver.
      [application] <Usermode--Kernalmode> [ software driver] <--> (protected data)
    - Software drivers always run in kernal mode, They're primarily written to access protected data only available in kernal mode. However, not all device drivers need access to kernal-mode data and resources, some device derivers run in user mode.
      https://learn.microsoft.com/en-us/windows-hardware/drivers/gettingstarted/user-mode-and-kernel-mode

  - Bus Drivers

    - Another type of driver is the bus driver. To understand bus drivers, you need to understand device nodes and the device tree.
      https://learn.microsoft.com/en-us/windows-hardware/drivers/gettingstarted/device-nodes-and-device-stacks

  - More information on Function Drivers:

    - Our explanation so far oversimplifies the definition of function driver. We stated that the function driver for a device is the one driver in the stack that communicates directly withthe device. This is true for a device that connects directly to the Peripheral Component Interconnnect (PCI) bus. The function driver for a PCI device obtains addresses that are mapped to port and memory resources on the device. The function driver communicates directly with the device by writing to those addresses.
      However, in many cases, a device doesn't connect directly to the PCI bus. instead, the device connects to a host bus adapeer that is connected to the PCI bus. For example, a USB toaster connects to a host bus adapter (called a USB host controller), whichis connected to the PCI bus. The USB toaster has a function driver, and the USB host controller also has a function driver. The function driver for the toaster communicates inderectly with the toaster by sending a request to the function driver for the USB host controller. The function driver for the USB host controller then communicates directly with the USB host controller hardware, which communicates with the toaster.
      [filter driver] <--> [Function Driver] <--Otherdrivers--> [Function Driver for USB host controller] <--> (USB host controller) <--> (USB Toaster)

  - Best Practices for managing RAM usage in high-level applications:
    https://learn.microsoft.com/en-us/azure-sphere/app-development/application-memory-usage?view=azure-sphere-integrated&tabs=windows&pivots=visual-studio

    - Allocate memory upfront (ideally statically) and leave it allocated for the lifetime of your application whenever possible. This will greatly increase the determinism of your application's RAM usage, and reduce the risk fo memory footprint increases and fragmentation over you application's lifetime.
    - When dynamic allocation is absolutley necessary:
      - Try to minimize the frequency of heap memory allocations and deallocation that are being performed by the application to reduce risks of heap memory fragmentation, for example, by leveraging chunck allocation/memory pool techniques.
      - Review stack pages and when possible, wrap calls to malloc() with calls to memset() to force pages to commit. This helps unsure that if an allocation causes your application to exceed its RAM limit, the OS will terminate it immediately and predictably. Waiting to access allocated pages will introduce the risk of a delayed out-of-memory crash, which is harder to reproduce and diagnose.
      - Enable heap memory allocation tracking while in development mode.
        https://learn.microsoft.com/en-us/azure-sphere/app-development/application-memory-usage?view=azure-sphere-integrated&tabs=windows&pivots=visual-studio#add-heap-memory-allocation-tracking
    - Avoid using Log_Debug with large strings and remove these alls (for example, with an #ifdef) when not in development mode. Log_Debug causes temporary buffers to be allocated, leading to sudden bursts in RAM usage when used with large strings.
    - Use th EventLoop API whenever possible for periodic asynchronous tasks (such as iteracting with peripherals) instead of creating threads. Creating threads causes the Linux kernal to allocate additional memory attributed to your application. This reduces the determinism of your app as it increases the probability of the OS sceduler switching between multiple, distinct operations that may cause your application to exceed its RAM limit. Many of the Azure Sphere Sample Applications such as the GPIO_HighLevelApp, demonstrate how to use the EventLoop.
    - Avoid premature use of memory caches for values that an be recomputed in runtime.
    - While using Libcurl:
      - Tune the max socket buffer sizes when using libcurl. Azure Sphere OS will allocate sockets buffers that are attributed to your application's RAM footprint of your application.
        Note that making the socket buffers too small will adversely impant the performance of libcurl. Instead, tune the max buffer sizes for your scenario:

    static int sockopt_callback(void* clientp, curl_socket_t curlfd, curlsocktype purpose)
    {
    int size = /*specify max buffer sizes here (in bytes)\*/
    int size_size = sizeof(size);
    setsockopt(curlfd, SOL_SOCKET, SO_SNDBUF, &size, &size_size);
    setsockopt(curlfd, SOL_SOCKET, SO_RCVBUF, &size, &size_size);
    return CURL_SOCKOPT_OK;
    }

    // Place the following along with other calls to curl_easy_setopt
    curl_easy_setopt(curl, CURLOPT_SOCKOPTFUNCTION, &sockopt_callback);

  - see the CURLOPT_SOCKOPTFUNCTION libcurl doc:
    https://curl.se/libcurl/c/CURLOPT_SOCKOPTFUNCTION.html

    The higher-level CURLOPT_BUFFERSIZE and CURLOPT_UPLAOD_BUFFERSIZE parameters can be similarly tuned.

  - Libcurl also supports overriding its internal memory functions by using curl_global_init_mem and passing in callback functions for malloc, free, realloc, strdup, and calloc. This functionality enables you to allocate libcurl memory from that pool. This can be an effective technique for setting guardrails and increasing determinism of your application. See https://curl.se/libcurl/c/curl_global_init_mem.html got more information on how to use the callbacks.

- CPU Analysis:

  - Background: Modern computers can contain multiple CPUs that are installed in separate sockets. Each CPU can host multiple physical processor cores, each capable of processing one or two separate instruction streams simultaneously. These individual instruction stream processors are managed by the Windows operating system as logical processors.
    Logical Processor: a hardware device that the operating system can use to execute program instuctions.
    Windows 10 actively manages processor hardware in two main ways: power management, to balance power consumption and performance; and usage, to balance the processing requirement s of programs and drivers.

  - Processor Power Management: Processors do not always exist in an operating state. When no instructions are ready to execute, Windows will put a processor into a target idle stat(or C-State), as determined by the Windows Power Manager. Based on CPU usage patterns, a processor's target C-state will be adjusted over time.
    Idle states are numbered states form C0 (active; no idle) throught progressively lower-power states. These states include C1 (halted but the clock is still enabled), C2 ( halted and the clock is disabled), and so forth. The implementation of idle states is processor specific. However, a higher state number in all processors relfects lower power consumption, but also a longer wait time before the processor can return to unstruction processing. Time that is spend in idle states significantly affcts energy use and battery life.
    Some processors can operate in performance (P-) and throttle (T-) states even when they are actively processing instructions. P-states define the clock frequencies and voltage levels the processor supports. T-states do not directly change the clock frequency, but can lower the effective clock speed by skipping processing activity on soem fraction of clock ticks. Together, the current P- and T- states determine the effective operating frequency of the processor. Lower frequencies correspond to lower performce and lower power consumption.
    The Windows Power Manager determines an appropriate P- and T- state for each processor, based on CPU usage patterns and system power policly. Time that is spent in high-performance states versus low-performance states significantly affects energy use and battery life.

  - Processor Usage Management:
    - Windows uses three major abstractions to manage processor usage:
      Proccess, Threads, ad Deferred Procedure Calls (DPCs) and Interrupt Service Routines (IRSs)
  - Processes and Threads:
    - All user-mode programs in Windows run in the context of a process. A process includes the following attributes and components:
      - A virtual address space
      - Priority class
      - Loaded program modules
      - Environment and configuration information
      - At least one thread
    - Although processes contain the program modules, context and environment, they are not directly scheduled to run on a processor. Instead, threads that are owned by a process are scheduled to run on a processor.
    - A Thread maintains execution context information. Almost all computation is managed as part of a thread. Thread activity fundamentally affects measurements and system performance.
    - Because the number of processors in a system is limited, all threads cannont be run at the same time. Windows implements processor time-sharing, which allows a thread to run for a period of time before the processor switches to another thread. The act of swithcing between threads is called a context-switch and it is performed by a Windows component called the dispatcher. The dispatcher makes thread scheduling decisions based on priority, ideal processor and affinity, quantum, and state.
  - Priority:
    - Priority is a key factor in how the dispatcher selects which thread to run. Thread priority is an integer from 0 to 31. If a thread is executable and has a higher priority than a currently running thread the lower-priority thread is immediatly preempted and the highter-priority thread is context-switched in.
    - When a thread is running or is ready to run, no lower-priority threads can run unless there are enough preocessors to run both threads at the same time, or unless the higher-priority thread is restricted to run on only a subset of available processors. Threads have a base priority that can be temporarily elevated to higher priorities at certain times: for example, when the process owns the froeground window, or when an I/O completes.
  - Ideal Processor and Affinity:

    - A thread's ideal processor and affinity determine the processors on which a given thread is scheduled to run. Each thread has an ideal processor that is set either by the program or automatically by Windows. Windows uses a round-robin methodology so that an approximately equal number of threads in each process are assigned to each processor. When possible, Windows schedules a thread torun on its ideal processor; however, the thread can occasionally run on other processors.
    - A thread's processor affinity restricts the processors on which a thread will run. This is a stronger restriction that the thread's ideal processor attribute. The program sets affintiy by using SetThreadAffintiyMask. Affinity can prevent threads from ever running on particular processors.

  - Quantum:

    - Context switches are expensive operations. Windows generally allows each thread to run for a period of time that is called a quantum before it switches to another thread. Quantum duration is designed to preserve apparent system responsiveness. It maximizes throughput by minimizing the overhead of context switching. Quantum durations can vary between clients and server. Quantum durations are typically longer on a server to maximize throughput at the expense of apparent responsiveness. On client computers, Windows assigns shorter quantums overall, but provides alonger quantum to the thread associated with the current foreground windows.

  - State:
    - Each thread exists in a particular execution state at any given time. Windows uses three states that are relevant to performance; these are: Running, Ready, and Waiting.
    - Threads that are currently being executed are in the Running state. Threads that an execute but are urrently not running are in the Ready state. Threads that cannont run because they are waiting for a particular event are in the Waiting state.
    - Thread State Transitons is explained as follows:
    - A thread in thr Running state initiates a transition to the Waiting state by calling a wait funcion such as WaitForSingleObject or Sleep (>0).
    -
